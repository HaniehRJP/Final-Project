{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7f85c0-e14e-4809-a171-a418ea04278a",
   "metadata": {},
   "source": [
    "## IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f898f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for data analysis and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "\n",
    "#for model creation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,  ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,  ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.feature_selection import RFE\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.linear_model import Lasso,Ridge,ElasticNet\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e14c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#concating 2 files to use test/train split\n",
    "\n",
    "data = \"https://raw.githubusercontent.com/HaniehRJP/Final-Project/main/customer_conversion_traing_dataset%20.csv\"\n",
    "df = pd.read_csv(data)\n",
    "df_test_link='https://raw.githubusercontent.com/HaniehRJP/Final-Project/main/customer_conversion_testing_dataset.csv'\n",
    "df_test=pd.read_csv(df_test_link)\n",
    "df=pd.concat([df, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b2411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec62d7-22fc-42f3-9fcb-3c62173a5cea",
   "metadata": {},
   "source": [
    "## CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca956d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NAs\n",
    "\n",
    "def null_check(data_frame):\n",
    "    print(f'Total null values per row: \\n{data_frame.isnull().sum(axis=1)}\\n')\n",
    "    print(f'Total null values per column: \\n{data_frame.isnull().sum()}\\n')\n",
    "\n",
    "null_check(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb0dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Duplicates check\n",
    "\n",
    "def dup_check(data_frame):\n",
    "    print(f'Duplicates found: {data_frame.duplicated().any()}\\n')\n",
    "    print(f'Number of duplicates: {data_frame.duplicated().sum()}\\n')\n",
    "    \n",
    "dup_check(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a3c38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#colmns optimization\n",
    "\n",
    "#renaming\n",
    "df.rename(columns={\"TimeSpent (minutes)\":\"TimeSpent\"}, inplace=True)\n",
    "df.rename(columns={\"Conversion (Target)\":\"Conversion\"}, inplace=True)\n",
    "\n",
    "#recalculating\n",
    "df['ResponseTime'] = df['ResponseTime (hours)'] * 60\n",
    "\n",
    "# Drop the original 'ResponseTime (hours)' column\n",
    "df.drop(columns=['ResponseTime (hours)', 'Location', 'ReferralSource', 'LeadStatus', 'LeadID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80adfaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a2fb56-883c-4eae-aae3-099455a37b77",
   "metadata": {},
   "source": [
    "## ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fcf1ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categoricals = df.select_dtypes(include=[object, bool])\n",
    "categoricals.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133a5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numericals = df.select_dtypes(include = 'number')\n",
    "numericals.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913c935",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordinals = categoricals[['PaymentHistory']]\n",
    "ordinals.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c913d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordinals = categoricals['PaymentHistory'].map({'Good':1, 'No Payment':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2933f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nominals = categoricals.drop(columns=['PaymentHistory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8051c349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nominals.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262cf1a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#making dunnies from nominals\n",
    "\n",
    "nominals = pd.get_dummies(nominals, dtype=int)\n",
    "nominals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c6a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categoricals = pd.concat([ordinals, nominals], axis=1)\n",
    "categoricals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040da086",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([categoricals, numericals], axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36915141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c53a9850-a379-4886-b56c-eaf2d022e5da",
   "metadata": {},
   "source": [
    "## TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34f7d1-a2f0-44cd-ab98-ddd32cff282b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#splitting into X and y\n",
    "X=df.drop(columns=[\"Conversion\"])\n",
    "y=df[[\"Conversion\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d542d352-1457-497d-a6aa-2ff2b910d2a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train and test split\n",
    "X_train, X_test,y_train, y_test=train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2eac54-4947-46a4-8ecf-6c51b126c9d2",
   "metadata": {},
   "source": [
    "## DOWNSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e26fb04-8e7b-4a16-b238-696a542f1ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train=pd.concat([X_train, y_train], axis=1)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188bc960-1cdf-413a-846c-de476df7503a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#downsampling\n",
    "category_0 = df_train[df_train['Conversion'] == 0] # negative class (majority)\n",
    "category_1 = df_train[df_train['Conversion'] == 1] # positive class (minority)\n",
    "\n",
    "print(category_0['Conversion'].value_counts())\n",
    "print(category_1['Conversion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb33317-2fa6-42bc-ac0b-9d360efa39b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c1_len=5000\n",
    "category_0_down = category_0.sample(c1_len)\n",
    "print(category_0_down.shape)\n",
    "print(category_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506d99f5-f6c7-44c0-8834-67c89370d06c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reassemble the data\n",
    "df_train = pd.concat([category_0_down, category_1], axis=0)\n",
    "# shuffle the data\n",
    "df_train = df_train.sample(frac=1) # frac specifies ratio of the shuffled output to the input size. for frac=1 the number of rows is unchanged\n",
    "df_train['Conversion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59234f1e-1979-4d42-86d6-a87de6084241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a1139d-550c-4839-8fa6-233985a0d0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train=df_train.drop(columns=[\"Conversion\"])\n",
    "y_train=df_train[[\"Conversion\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c92463-b0ff-42b7-afc3-4a10dda2fb29",
   "metadata": {},
   "source": [
    "## UPSAMPLE USING SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d183aa0-0d93-4b3a-b8a9-fc3070a335ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upsampling using SMOTE\n",
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6669e-36ab-4a73-929e-063c68b60bd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "y_train_sm.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384edfdc-93a4-4760-9d22-fb685e1bae62",
   "metadata": {},
   "source": [
    "## SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b567f49-9680-4d73-8b80-394578d139b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#scaling\n",
    "pt=PowerTransformer()\n",
    "pt.fit(X_train)\n",
    "X_train_pt=pt.transform(X_train_sm)\n",
    "X_test_pt=pt.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc5fbfc-6153-449b-8a76-e4c36ee89229",
   "metadata": {},
   "source": [
    "## LOGISTICS REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523abc9-141d-469e-af77-c36ed2c2c585",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fitting LOGISTICS REGRESSION\n",
    "\n",
    "weights = {0: 1, 1: 2}\n",
    "log_model = LogisticRegression(class_weight=weights) # weights to be added if we want to avoid fall negative or fall positive\n",
    "log_model.fit(X_train_pt, y_train_sm)\n",
    "\n",
    "# predicting data\n",
    "y_pred_train = log_model.predict(X_train_pt)\n",
    "y_pred_test = log_model.predict(X_test_pt)\n",
    "\n",
    "\n",
    "#results\n",
    "performance_log1 = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train_sm, y_pred_train),\n",
    "                                         precision_score(y_train_sm, y_pred_train),\n",
    "                                         recall_score(y_train_sm, y_pred_train)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test),\n",
    "                                        precision_score(y_test, y_pred_test),\n",
    "                                        recall_score(y_test, y_pred_test)]})\n",
    "\n",
    "display(performance_log1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9175ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_log1.to_csv('KNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce92918-c6de-4ab9-8fc9-3fcff907b732",
   "metadata": {},
   "source": [
    "## TRAIN SET CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3422e-79e4-4da8-ad76-7f0c823cbbf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(y_train_sm, y_pred_train, labels = log_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(cm_train)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b1590-cec0-4d75-83e0-daa5c05f2927",
   "metadata": {},
   "source": [
    "## TEST SET CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15a0b1-d1b5-48e6-aae1-025b1b2e8481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(y_test, y_pred_test, labels = log_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(cm_train)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a59c9-8637-465c-ae27-1e4533687ff9",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f141724-9449-491d-a4ca-c868d180d886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering out DataConversionWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "accuracy = {}  # Dictionary to store best accuracies\n",
    "precision = {} # Dictionary to store best precision\n",
    "recall={} # Dictionary to store best recalls\n",
    "\n",
    "# Iterating over different numbers of selected features\n",
    "for num_features in range(10, 21):  # Considering up to 10 features\n",
    "    \n",
    "    selector = RFE(log_model, n_features_to_select=num_features, step=1, verbose=1)\n",
    "    selector.fit(X_train_pt, y_train_sm)\n",
    "    \n",
    "    weights = {0: 1, 1: 2}\n",
    "    log_model = LogisticRegression(class_weight=weights)\n",
    "    \n",
    "    # Transforming the data\n",
    "    X_train_RFE = selector.transform(X_train_pt)\n",
    "    X_test_RFE = selector.transform(X_test_pt)\n",
    "    \n",
    "    # Fitting the model\n",
    "    log_model.fit(X_train_RFE, y_train_sm)\n",
    "    \n",
    "    # Predicting and calculating R2 score\n",
    "    y_pred_test= log_model.predict(X_test_RFE)\n",
    "    acc=accuracy_score(y_test, y_pred_test)\n",
    "    rec=recall_score(y_test, y_pred_test)\n",
    "    prec=precision_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Storing the best R2 score for each number of selected features\n",
    "    accuracy[num_features] = acc\n",
    "    precision[num_features]=prec\n",
    "    recall[num_features]=rec\n",
    "\n",
    "# Printing the best R2 score for each number of selected features\n",
    "for num_features, acc in accuracy.items():\n",
    "    prec = precision[num_features]\n",
    "    rec = recall[num_features]\n",
    "    print(f\"Number of Features: {num_features}, Accuracy: {acc}, Precision: {prec}, Recall: {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b3edc-591e-4ee0-93ce-f42487bf220d",
   "metadata": {},
   "source": [
    "### best decision according to RFE is keeping all 20 features\n",
    "##### Accuracy: 0.750642102926721, Precision: 0.05739381542533991, Recall: 0.9408284023668639"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aff3a34-5453-4c70-8096-8e2d08da2397",
   "metadata": {},
   "source": [
    "## LASSO, RIDGE, ELASTICNET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfdaba2",
   "metadata": {},
   "source": [
    "- LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accb00c-8cd1-44df-a03b-da6bb79282b7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initializing Logistic Regression model with Lasso regularization\n",
    "log_model_lasso = LogisticRegression(penalty='l1', solver='liblinear', class_weight=weights)\n",
    "\n",
    "# Fitting the model to your data\n",
    "log_model_lasso.fit(X_train_pt, y_train_sm)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_lasso = log_model_lasso.predict(X_test_pt)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred_lasso)\n",
    "precision = precision_score(y_test, y_pred_lasso)\n",
    "recall = recall_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Printing evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a32253",
   "metadata": {},
   "source": [
    "- RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb1cd7-2216-45ba-b076-863ae6839c40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initializing Logistic Regression model with Lasso regularization\n",
    "log_model_ridge = LogisticRegression(penalty='l2', solver='liblinear', class_weight=weights)\n",
    "\n",
    "# Fitting the model to your data\n",
    "log_model_ridge.fit(X_train_pt, y_train_sm)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_ridge = log_model_ridge.predict(X_test_pt)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred_ridge)\n",
    "precision = precision_score(y_test, y_pred_ridge)\n",
    "recall = recall_score(y_test, y_pred_ridge)\n",
    "\n",
    "# Printing evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e72e7",
   "metadata": {},
   "source": [
    "- ELASTICNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae95a25-15e9-4979-a0d9-66d156529117",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initializing Logistic Regression model with Lasso regularization\n",
    "log_model_elasticnet = LogisticRegression(penalty='elasticnet', solver='saga',l1_ratio=0.5, class_weight=weights)\n",
    "\n",
    "# Fitting the model to your data\n",
    "log_model_elasticnet.fit(X_train_pt, y_train_sm)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_elasticnet = log_model_elasticnet.predict(X_test_pt)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred_elasticnet)\n",
    "precision = precision_score(y_test, y_pred_elasticnet)\n",
    "recall = recall_score(y_test, y_pred_elasticnet)\n",
    "\n",
    "# Printing evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe8f532",
   "metadata": {},
   "source": [
    "## Fit a KNN Classifier model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c76e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating KNN Classifier model\n",
    "\n",
    "model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080b2c74",
   "metadata": {},
   "source": [
    "### Optimizing the Weighting Scheme for K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1144199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a custom weight function\n",
    "\n",
    "def custom_weight_function(distances):\n",
    "    \n",
    "    #Giving more weight to class 1\n",
    "    \n",
    "    weights = np.where(distances == 0, 5, 0.5)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c190924",
   "metadata": {},
   "source": [
    "### Implementing Grid Searching for Number of Neighbors Optimization in KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bbd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter grid for grid search and get the best model and fit the model\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(2, 21)),  # Range from 2 to 20\n",
    "    'weights': [custom_weight_function, 'uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='recall')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_pt, y_train_sm)  # Assuming X_train and y_sm are your training data\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Now, best_model is the KNeighborsClassifier with the best hyperparameters\n",
    "# You can use it for predictions on the test set\n",
    "y_pred = best_model.predict(X_test)  # Assuming X_test is your test data\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_pt, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc9acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate KNN Classifier model\n",
    "model = KNeighborsClassifier(n_neighbors=19,weights='distance')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_pt, y_train_sm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092219e8",
   "metadata": {},
   "source": [
    "### Predicting on the test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc38c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(X_test) # predict test\n",
    "y_pred_train=model.predict(X_train_pt) # predict train (for sanity checks)\n",
    "\n",
    "# Evaluate performance\n",
    "performance_log = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train_sm, y_pred_train),\n",
    "                                         precision_score(y_train_sm, y_pred_train),\n",
    "                                         recall_score(y_train_sm, y_pred_train)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test),\n",
    "                                        precision_score(y_test, y_pred_test),\n",
    "                                        recall_score(y_test, y_pred_test)]})\n",
    "\n",
    "display(performance_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659f5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_log.to_csv('KNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507ea32",
   "metadata": {},
   "source": [
    "### TRAIN SET CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e06b99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train_sm, y_pred_train, labels= model.classes_)\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793921f9",
   "metadata": {},
   "source": [
    "### TEST SET CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ec61c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_test, labels = model.classes_)\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8879c",
   "metadata": {},
   "source": [
    "## RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducible shuffling\n",
    "RAND_STATE = 42\n",
    "\n",
    "# test/train\n",
    "TT_RATIO = 0.25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a403a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rfc_ops = {\"max_depth\":6,\n",
    "           \"min_samples_leaf\":20,\n",
    "           \"n_estimators\":100,\n",
    "           \"bootstrap\":True,\n",
    "           \"oob_score\":True,\n",
    "           \"random_state\":RAND_STATE}\n",
    "\n",
    "class_weights = {0: 1, 1: 2}  # Adjust weights as needed\n",
    "clf = RandomForestClassifier(class_weight=class_weights, **rfc_ops)\n",
    "\n",
    "clf.fit(X_train_sm, y_train_sm)\n",
    "print(\"train prediction accuracy score: %.2f\" %(clf.score(X_train_sm, y_train_sm)))\n",
    "print(\"test prediction accuracy score: %.2f\"  %(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b5bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing Out-of-Bag Score for Performance Evaluation in RandomForestClassifier\n",
    "clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4902a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the accuracy score of the model on the test set\n",
    "score_ds = accuracy_score(y_test,clf.predict(X_test))\n",
    "score_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4994425d",
   "metadata": {},
   "source": [
    "### Investigating Hyperparameter Tuning with Grid Search and Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bc87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the GridSearchCV object\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': list(range(2, 12)), \n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "# Fitting the model\n",
    "grid_search.fit(X_train_sm,y_train_sm)  # Assuming X_train and y_sm are your training data\n",
    "\n",
    "# Printing the best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# predicting on the test set\n",
    "y_pred = best_model.predict(X_test)  # Assuming X_test is your test data\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a0c070",
   "metadata": {},
   "source": [
    "### Fitting a RandomForest Classifier with Optimized Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd415d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_ops = {\"max_depth\":11,\n",
    "           \"min_samples_leaf\":1,\n",
    "           'min_samples_split': 2,\n",
    "           \"n_estimators\":100,\n",
    "           \"oob_score\":True,\n",
    "           \"random_state\":42}\n",
    "\n",
    "class_weights = {0: 2.5, 1: 1}  # Adjust weights as needed\n",
    "clf = RandomForestClassifier(class_weight=class_weights, **rfc_ops)\n",
    "\n",
    "        #max_depth=6,min_samples_leaf=20,max_features=None,n_estimators=100,\n",
    "         #                    bootstrap=True,oob_score=True, random_state=RAND_STATE)\n",
    "clf.fit(X_train_sm, y_train_sm)\n",
    "print(\"train prediction accuracy score: %.2f\" %(clf.score(X_train_sm, y_train_sm)))\n",
    "print(\"test prediction accuracy score: %.2f\"  %(clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a2eb8",
   "metadata": {},
   "source": [
    "### Predicting on the test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3da5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test) # predict test\n",
    "y_pred_train=clf.predict(X_train_sm) # predict train (for sanity checks)\n",
    "\n",
    "# Evaluate performance\n",
    "performance_log2 = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train_sm, y_pred_train),\n",
    "                                         precision_score(y_train_sm, y_pred_train),\n",
    "                                         recall_score(y_train_sm, y_pred_train)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred),\n",
    "                                        precision_score(y_test, y_pred),\n",
    "                                        recall_score(y_test, y_pred)]})\n",
    "\n",
    "display(performance_log2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb467b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_log2.to_csv('RandomForest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec38d72e",
   "metadata": {},
   "source": [
    "### Visualizing Accuracy and Recall Performance Based on Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_test, labels = clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78fb942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
